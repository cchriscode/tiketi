# "100만 명이 몰리는 것도 트래픽 아니야?" 완벽 해설
> **대기열 등록 vs 실제 처리의 차이**

---

## 🤔 핵심 질문

**"100만 명이 접속하면 그 자체가 트래픽이잖아? 어떻게 서버에 대기시키는 거야?"**

**답변: 맞아요! 하지만 트래픽에도 "가벼운 트래픽"과 "무거운 트래픽"이 있어요!**

---

## 💡 핵심 개념: 작업의 무게

### 가벼운 작업 (Light Operation) ⚡

```
대기열 등록:
  1. Redis에 데이터 쓰기
     ZADD queue:event-123 timestamp user-456

  2. 순번 조회
     ZRANK queue:event-123 user-456

  3. 응답 반환
     { queued: true, position: 8245 }

소요 시간: 0.01 ~ 0.05초
CPU 사용: 거의 없음
메모리 사용: 100 bytes
DB 연결: 필요 없음
```

### 무거운 작업 (Heavy Operation) 🏋️

```
티켓 구매 처리:
  1. DB 트랜잭션 시작
  2. 좌석 잠금 (FOR UPDATE)
  3. 재고 확인
  4. 사용자 잔액 확인
  5. 결제 처리
  6. 좌석 상태 업데이트
  7. 예매 기록 생성
  8. 트랜잭션 커밋
  9. WebSocket 브로드캐스트
  10. 이메일 발송

소요 시간: 1 ~ 3초
CPU 사용: 높음
메모리 사용: 수 KB
DB 연결: 필요 (동시성 제한됨)
```

---

## 📊 실제 처리 능력 비교

### EC2 1대가 처리 가능한 요청 수

```
대기열 등록 (가벼운 작업):
  초당 10,000건 가능
  ↓
  Redis 메모리 작업만 하면 되니까 엄청 빠름!

티켓 구매 (무거운 작업):
  초당 100건 가능
  ↓
  DB 트랜잭션, 잠금, 로직 처리... 느림!

차이: 100배!
```

### 100만 명 접속 시나리오

**시나리오 1: 대기열 없이 모두 티켓 구매 시도 (❌)**

```
100만 명이 동시에 티켓 구매 버튼 클릭
  ↓
EC2 10대가 처리 시도
  - 초당 처리: 100건 × 10대 = 1,000건
  ↓
100만 건 처리 시간: 1,000,000 ÷ 1,000 = 1,000초 (16분!)
  ↓
하지만 DB 연결 제한: 최대 200개
  ↓
DB 연결 풀 고갈 💥
타임아웃 폭발 💥
서버 다운 💥

→ 아무도 못 사요!
```

**시나리오 2: 대기열 사용 (✅)**

```
100만 명이 동시에 접속
  ↓
EC2 10대가 "대기열 등록" 처리
  - 초당 처리: 10,000건 × 10대 = 100,000건
  ↓
100만 건 등록 시간: 1,000,000 ÷ 100,000 = 10초!
  ↓
모두 대기열에 등록 완료 ✅
  - Redis 메모리: 100MB 사용
  - 서버 CPU: 20%
  - DB 연결: 0개 (아직 사용 안 함)
  ↓
이제 천천히 1,000명씩만 입장시켜서
실제 티켓 구매 처리
  ↓
서버 안정적 운영 ✅
```

---

## 🎯 왜 대기열 등록은 빠른가?

### 1. 메모리 작업만 수행

```
Redis (메모리 DB):
  - 디스크 접근 없음
  - 네트워크만 거침
  - 초당 10만 건 처리 가능

PostgreSQL (디스크 DB):
  - 디스크 I/O 필요
  - 트랜잭션 관리
  - 초당 1,000건 처리 가능

차이: 100배!
```

### 2. 복잡한 로직 없음

```
대기열 등록:
  ZADD queue:event-123 timestamp user-456
  → 끝!

티켓 구매:
  1. 재고 확인
  2. 중복 구매 체크
  3. 좌석 중복 체크
  4. 사용자 권한 체크
  5. 결제 처리
  6. 재고 차감
  7. 예매 생성
  8. 알림 발송
  → 8단계!
```

### 3. DB 연결 불필요

```
대기열 등록:
  Redis만 사용
  ↓
  DB 연결 풀 절약
  ↓
  동시성 제한 없음

티켓 구매:
  PostgreSQL 필요
  ↓
  DB 연결 풀: 최대 200개
  ↓
  동시에 200명만 처리 가능
```

---

## 📈 실제 숫자로 보기

### 100만 명 접속 시 리소스 사용량

**대기열 등록 단계 (10초):**

```
EC2 10대:
  CPU: 평균 30%
  메모리: 각 1GB (총 10GB)
  네트워크: 100 Mbps

Redis:
  메모리: 100MB (100만 명 × 100 bytes)
  CPU: 50%
  처리량: 초당 10만 건

PostgreSQL:
  사용량: 0% (아직 사용 안 함!)

ALB:
  요청 수: 초당 10만 건
  자동 확장: AWS가 알아서 처리

→ 모든 리소스가 여유로움!
```

**만약 대기열 없이 모두 티켓 구매 시도했다면:**

```
EC2 10대:
  CPU: 100% (과부하!)
  메모리: 4GB (OOM!)
  네트워크: 1 Gbps (포화!)

Redis:
  CPU: 80%
  메모리: 2GB

PostgreSQL:
  CPU: 100% (과부하!)
  메모리: 8GB (스와핑!)
  연결 수: 200/200 (포화!)
  대기 큐: 99,800개 (타임아웃!)

→ 시스템 전체 다운! 💥
```

---

## 🔍 상세 비교: 요청당 리소스

### 대기열 등록 요청 1건

```
사용자 요청:
  POST /api/queue/check/123
  Body: (없음, JWT만)
  크기: 1 KB

서버 처리:
  1. JWT 검증 (메모리, 0.001초)
  2. Redis 쓰기 (네트워크 + 메모리, 0.01초)
  3. Redis 읽기 (네트워크 + 메모리, 0.01초)
  4. 응답 반환 (0.005초)

총 소요 시간: 0.026초 (26ms)
메모리: 100 bytes
CPU: 0.01%
DB 연결: 0개

→ 가벼움! ⚡
```

### 티켓 구매 요청 1건

```
사용자 요청:
  POST /api/reservations/create
  Body: { seatIds: [1,2,3], ticketTypeId: 1 }
  크기: 2 KB

서버 처리:
  1. JWT 검증 (0.001초)
  2. DB 트랜잭션 시작 (0.01초)
  3. 좌석 잠금 SELECT FOR UPDATE (0.1초)
  4. 재고 확인 (0.05초)
  5. 중복 체크 (0.05초)
  6. 예매 생성 INSERT (0.1초)
  7. 좌석 업데이트 UPDATE (0.1초)
  8. 트랜잭션 커밋 (0.2초)
  9. Redis 캐시 무효화 (0.01초)
  10. WebSocket 브로드캐스트 (0.05초)
  11. 응답 반환 (0.005초)

총 소요 시간: 0.676초 (676ms)
메모리: 5 KB
CPU: 1%
DB 연결: 1개 (200개 제한)

→ 무거움! 🏋️

26배 느림!
```

---

## 🌊 트래픽 흐름 비교

### 대기열 없이 (❌)

```
시간    요청     서버 상태              DB 상태
───────────────────────────────────────────────
0초    100만    수용 불가              연결 폭발
1초    처리 중   CPU 100%              데드락 발생
2초    타임아웃  메모리 부족            응답 없음
3초    서버 다운 💥                    다운 💥

→ 아무도 못 사요!
```

### 대기열 사용 (✅)

```
시간    요청     대기열           활성      서버 CPU    DB
─────────────────────────────────────────────────────────
0초    10만    10만 등록         0        30%        0%
1초    10만    20만 등록         0        30%        0%
2초    10만    30만 등록         0        30%        0%
...
10초   10만    100만 등록        0        30%        0%
       ✅ 등록 완료!

이제 천천히 입장 시작:
10초         100만         1,000    40%        20%
11초         99만          1,000    40%        20%
12초         98만          1,000    40%        20%
...
1,000초      0명           1,000    40%        20%
       ✅ 모두 처리 완료!

→ 안정적으로 모두 처리! ✅
```

---

## 💭 "그럼 100만 명이 대기열 등록하는 것도 트래픽 아니야?"

**맞아요! 하지만:**

### 1. 훨씬 가볍고 빠른 트래픽

```
대기열 등록 트래픽:
  - 초당 10만 건 처리 가능
  - 10초면 100만 명 등록 완료
  - 서버 CPU 30%
  - 안정적!

티켓 구매 트래픽:
  - 초당 1,000건 처리 가능
  - 1,000초 필요 (16분)
  - 서버 CPU 100%
  - 위험!
```

### 2. 순간 폭발 vs 분산 처리

```
대기열 없이:
  100만 명이 동시에 DB 접근 시도
  → DB 연결 200개 제한
  → 즉시 포화
  → 시스템 다운 💥

대기열 사용:
  100만 명이 메모리에만 등록
  → DB는 아직 건드리지 않음
  → 천천히 1,000명씩 DB 처리
  → 시스템 안정 ✅
```

### 3. 실제로는 동시 접속 불가능

```
현실:
  "100만 명이 동시에" 는 불가능

  실제로는:
  - 1분 동안 10만 명 정도
  - 10분 동안 100만 명

  ALB + EC2 10대:
  - 초당 10만 건 처리 가능
  - 10만 명/분은 충분히 처리 가능

  그래서 대기열 시스템이 작동하는 거예요!
```

---

## 🎯 결론

### 질문: "100만 명이 몰리면 그것도 트래픽 아니야?"

**답변: 맞아요! 하지만:**

```
✅ 대기열 "등록" 트래픽: 가벼움
   - Redis 메모리 작업만
   - 초당 10만 건 처리 가능
   - 100만 명도 10초면 등록 완료
   - 서버 안정적

❌ 티켓 "구매" 트래픽: 무거움
   - DB 트랜잭션 필요
   - 초당 1,000건만 처리 가능
   - 100만 명은 16분 필요
   - 동시 처리 시 서버 다운

→ 대기열은 "무거운 트래픽"을 "가벼운 트래픽"으로 변환해요!
```

### 메모리에 저장되는 건 맞지만:

```
Redis 메모리 작업 (빠름):
  - 네트워크 지연만 있음
  - 디스크 접근 없음
  - 락 대기 없음
  - 초당 10만 건

PostgreSQL DB 작업 (느림):
  - 디스크 I/O
  - 트랜잭션 관리
  - 락 대기
  - 초당 1,000건

차이: 100배!
```

### 핵심 비유:

```
대기열 시스템 = 은행 번호표

100만 명이 은행에 몰림:

방법 1 (대기열 없이):
  모두 창구로 달려듦
  → 난장판 💥
  → 아무도 업무 못 봄

방법 2 (대기열 사용):
  번호표 기계에서 번호표 받음 (빠름! 1초)
  → 100만 명도 10초면 번호표 받음
  → 그 다음 천천히 창구에서 업무 (느림, 5분)
  → 질서있게 모두 처리 ✅

번호표 받는 건 가벼운 작업!
실제 업무는 무거운 작업!
```

**대기열 등록 자체는 트래픽이지만,**
**"처리 가능한" 가벼운 트래픽이라는 게 핵심이에요!** 🎯