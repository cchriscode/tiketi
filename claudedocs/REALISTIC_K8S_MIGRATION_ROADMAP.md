# í˜„ì‹¤ì ì¸ K8s ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡œë“œë§µ
## EC2 â†’ K8s í•™ìŠµ ì¤‘ì‹¬ ì ‘ê·¼ë²•

---

## ğŸ¯ ì „ì œ ì¡°ê±´

**í˜„ì¬ ìƒíƒœ**:
- âœ… EC2ì— Docker Composeë¡œ ë°°í¬ ì™„ë£Œ
- âœ… Frontend (React) + Backend (Node.js) + PostgreSQL + Redis
- âœ… ê¸°ë³¸ ê¸°ëŠ¥ ë™ì‘ ì¤‘

**ëª©í‘œ**:
- ğŸ“ K8s ì‹¤ì „ ê²½í—˜ ìŠµë“
- ğŸ“ MSA ê°œë… ì´í•´ (ê³¼ë„í•œ ë³µì¡ë„ ì—†ì´)
- ğŸ“ í¬íŠ¸í´ë¦¬ì˜¤ ê°•í™”
- ğŸ“ ì·¨ì—…/ì´ì§ ì¤€ë¹„

---

## ğŸ“… 3ë‹¨ê³„ í•™ìŠµ ë¡œë“œë§µ

### **1ë‹¨ê³„: ëª¨ë†€ë¦¬ì‹ K8s ë§ˆì´ê·¸ë ˆì´ì…˜** (2ì£¼)
**ëª©í‘œ**: K8s í•µì‹¬ ê°œë… ë§ˆìŠ¤í„°

### **2ë‹¨ê³„: ê²½ëŸ‰ MSA ì „í™˜** (2-3ì£¼)
**ëª©í‘œ**: ì‹¤ìš©ì  MSA íŒ¨í„´ í•™ìŠµ

### **3ë‹¨ê³„: ê³ ê¸‰ ê¸°ëŠ¥ ì¶”ê°€** (ì„ íƒ, 2ì£¼)
**ëª©í‘œ**: ì‹¬í™” ê¸°ìˆ  ìŠ¤íƒ

---

## ğŸš€ 1ë‹¨ê³„: ëª¨ë†€ë¦¬ì‹ K8s ë§ˆì´ê·¸ë ˆì´ì…˜ (2ì£¼)

### Week 1: EKS í´ëŸ¬ìŠ¤í„° êµ¬ì¶• ë° ê¸°ë³¸ ë°°í¬

#### Day 1-2: í™˜ê²½ ì¤€ë¹„

**1.1 í•„ìˆ˜ ë„êµ¬ ì„¤ì¹˜**

```bash
# Windows (PowerShell)
# AWS CLI
choco install awscli

# kubectl
choco install kubernetes-cli

# eksctl
choco install eksctl

# Kompose (Docker Compose â†’ K8s ë³€í™˜)
choco install kompose

# í™•ì¸
aws --version
kubectl version --client
eksctl version
kompose version
```

**1.2 í˜„ì¬ Docker Compose ë¶„ì„**

```bash
cd C:\Users\USER\project-ticketing

# Docker Compose íŒŒì¼ í™•ì¸
cat docker-compose.yml

# í˜„ì¬ êµ¬ì¡° íŒŒì•…
# - frontend: React ì•±
# - backend: Node.js API
# - postgres: PostgreSQL DB
# - redis: Redis ìºì‹œ
```

**1.3 Komposeë¡œ ìë™ ë³€í™˜**

```bash
# K8s YAML íŒŒì¼ ìë™ ìƒì„±
kompose convert -f docker-compose.yml -o k8s/generated/

# ìƒì„±ëœ íŒŒì¼ í™•ì¸
ls k8s/generated/
# â†’ frontend-deployment.yaml
# â†’ backend-deployment.yaml
# â†’ postgres-deployment.yaml
# â†’ redis-deployment.yaml
# â†’ frontend-service.yaml
# â†’ backend-service.yaml
# â†’ postgres-service.yaml
# â†’ redis-service.yaml
```

#### Day 3: EKS í´ëŸ¬ìŠ¤í„° ìƒì„±

**1.4 EKS í´ëŸ¬ìŠ¤í„° êµ¬ì„±**

```bash
# í´ëŸ¬ìŠ¤í„° ì„¤ì • íŒŒì¼ ì‘ì„±
cat > eks-cluster.yaml <<EOF
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: tiketi-cluster
  region: ap-northeast-2

nodeGroups:
  - name: tiketi-nodes
    instanceType: t3.medium
    desiredCapacity: 2
    minSize: 2
    maxSize: 4
    volumeSize: 20
    ssh:
      allow: false

# Managed Add-ons
addons:
  - name: vpc-cni
  - name: coredns
  - name: kube-proxy
EOF

# í´ëŸ¬ìŠ¤í„° ìƒì„± (15-20ë¶„ ì†Œìš”)
eksctl create cluster -f eks-cluster.yaml

# kubeconfig ì„¤ì • í™•ì¸
kubectl get nodes

# ì¶œë ¥:
# NAME                                            STATUS   ROLES    AGE
# ip-192-168-1-10.ap-northeast-2.compute.internal Ready    <none>   1m
# ip-192-168-2-20.ap-northeast-2.compute.internal Ready    <none>   1m
```

#### Day 4-5: ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬

**1.5 ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±**

```bash
mkdir -p k8s/base

cat > k8s/base/namespace.yaml <<EOF
apiVersion: v1
kind: Namespace
metadata:
  name: tiketi
EOF

kubectl apply -f k8s/base/namespace.yaml
```

**1.6 ConfigMap & Secrets ì‘ì„±**

```bash
# ConfigMap (ë¹„ë°€ì´ ì•„ë‹Œ ì„¤ì •)
cat > k8s/base/configmap.yaml <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: tiketi
data:
  NODE_ENV: "production"
  DB_HOST: "postgres-service"
  DB_PORT: "5432"
  DB_NAME: "tiketi"
  REDIS_HOST: "redis-service"
  REDIS_PORT: "6379"
  CORS_ORIGIN: "https://tiketi.gg"
EOF

# Secrets (ë¹„ë°€ë²ˆí˜¸, í† í°)
cat > k8s/base/secrets.yaml <<EOF
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: tiketi
type: Opaque
stringData:
  DB_USER: "tiketi_user"
  DB_PASSWORD: "<YOUR_DB_PASSWORD>"
  JWT_SECRET: "<YOUR_JWT_SECRET>"
  REDIS_PASSWORD: ""
  AWS_ACCESS_KEY_ID: "<YOUR_AWS_KEY>"
  AWS_SECRET_ACCESS_KEY: "<YOUR_AWS_SECRET>"
EOF

kubectl apply -f k8s/base/configmap.yaml
kubectl apply -f k8s/base/secrets.yaml
```

**1.7 PostgreSQL ë°°í¬ (StatefulSet)**

```bash
cat > k8s/base/postgres.yaml <<EOF
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-pvc
  namespace: tiketi
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: gp2
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
  namespace: tiketi
spec:
  serviceName: postgres-service
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:15
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_DB
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: DB_NAME
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: DB_USER
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: DB_PASSWORD
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
      volumes:
      - name: postgres-storage
        persistentVolumeClaim:
          claimName: postgres-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: postgres-service
  namespace: tiketi
spec:
  selector:
    app: postgres
  ports:
  - port: 5432
    targetPort: 5432
  clusterIP: None
EOF

kubectl apply -f k8s/base/postgres.yaml

# í™•ì¸
kubectl get pods -n tiketi -l app=postgres
kubectl logs -n tiketi postgres-0
```

**1.8 Redis ë°°í¬**

```bash
cat > k8s/base/redis.yaml <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
  namespace: tiketi
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        command: ["redis-server"]
        args: ["--appendonly", "yes"]
---
apiVersion: v1
kind: Service
metadata:
  name: redis-service
  namespace: tiketi
spec:
  selector:
    app: redis
  ports:
  - port: 6379
    targetPort: 6379
EOF

kubectl apply -f k8s/base/redis.yaml
```

**1.9 Backend ë°°í¬**

```bash
cat > k8s/base/backend.yaml <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
  namespace: tiketi
spec:
  replicas: 2
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
    spec:
      containers:
      - name: backend
        image: <YOUR_ECR_OR_DOCKERHUB>/tiketi-backend:latest
        ports:
        - containerPort: 3001
        env:
        - name: PORT
          value: "3001"
        - name: NODE_ENV
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: NODE_ENV
        - name: DB_HOST
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: DB_HOST
        - name: DB_NAME
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: DB_NAME
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: DB_USER
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: DB_PASSWORD
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: JWT_SECRET
        - name: REDIS_HOST
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: REDIS_HOST
        livenessProbe:
          httpGet:
            path: /health
            port: 3001
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 3001
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: backend-service
  namespace: tiketi
spec:
  selector:
    app: backend
  ports:
  - port: 80
    targetPort: 3001
  type: ClusterIP
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: backend-hpa
  namespace: tiketi
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: backend
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
EOF

kubectl apply -f k8s/base/backend.yaml
```

**1.10 Frontend ë°°í¬**

```bash
cat > k8s/base/frontend.yaml <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  namespace: tiketi
spec:
  replicas: 2
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: frontend
        image: <YOUR_ECR_OR_DOCKERHUB>/tiketi-frontend:latest
        ports:
        - containerPort: 3000
        env:
        - name: REACT_APP_API_URL
          value: "https://api.tiketi.gg"
---
apiVersion: v1
kind: Service
metadata:
  name: frontend-service
  namespace: tiketi
spec:
  selector:
    app: frontend
  ports:
  - port: 80
    targetPort: 3000
  type: ClusterIP
EOF

kubectl apply -f k8s/base/frontend.yaml
```

### Week 2: Ingress ë° ëª¨ë‹ˆí„°ë§

#### Day 1-2: Ingress Controller

**2.1 NGINX Ingress ì„¤ì¹˜**

```bash
# NGINX Ingress Controller ì„¤ì¹˜
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.1/deploy/static/provider/aws/deploy.yaml

# ì„¤ì¹˜ í™•ì¸
kubectl get pods -n ingress-nginx
kubectl get svc -n ingress-nginx

# LoadBalancer ì£¼ì†Œ í™•ì¸ (AWS ELB ìƒì„±ë¨)
kubectl get svc ingress-nginx-controller -n ingress-nginx
# ì¶œë ¥: EXTERNAL-IP (ì˜ˆ: a1b2c3d4...elb.amazonaws.com)
```

**2.2 Ingress ë¦¬ì†ŒìŠ¤ ìƒì„±**

```bash
cat > k8s/base/ingress.yaml <<EOF
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: tiketi-ingress
  namespace: tiketi
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  # API ì„œë²„
  - host: api.tiketi.gg
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: backend-service
            port:
              number: 80

  # í”„ë¡ íŠ¸ì—”ë“œ
  - host: tiketi.gg
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: frontend-service
            port:
              number: 80
EOF

kubectl apply -f k8s/base/ingress.yaml
```

**2.3 ë„ë©”ì¸ ì„¤ì • (Route 53)**

```bash
# Ingress LoadBalancer ì£¼ì†Œ í™•ì¸
INGRESS_LB=$(kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')

echo $INGRESS_LB
# ì¶œë ¥: a1b2c3d4...elb.amazonaws.com

# Route 53ì— CNAME ë ˆì½”ë“œ ì¶”ê°€:
# tiketi.gg â†’ $INGRESS_LB
# api.tiketi.gg â†’ $INGRESS_LB
```

#### Day 3-4: SSL ì¸ì¦ì„œ

**2.4 Cert-Manager ì„¤ì¹˜**

```bash
# Cert-Manager ì„¤ì¹˜
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.0/cert-manager.yaml

# í™•ì¸
kubectl get pods -n cert-manager
```

**2.5 Let's Encrypt Issuer ìƒì„±**

```bash
cat > k8s/base/cluster-issuer.yaml <<EOF
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: admin@tiketi.gg
    privateKeySecretRef:
      name: letsencrypt-prod
    solvers:
    - http01:
        ingress:
          class: nginx
EOF

kubectl apply -f k8s/base/cluster-issuer.yaml
```

**2.6 Ingressì— TLS ì¶”ê°€**

```bash
cat > k8s/base/ingress-tls.yaml <<EOF
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: tiketi-ingress
  namespace: tiketi
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  tls:
  - hosts:
    - tiketi.gg
    - api.tiketi.gg
    secretName: tiketi-tls
  rules:
  - host: api.tiketi.gg
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: backend-service
            port:
              number: 80
  - host: tiketi.gg
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: frontend-service
            port:
              number: 80
EOF

kubectl apply -f k8s/base/ingress-tls.yaml

# SSL ì¸ì¦ì„œ ë°œê¸‰ í™•ì¸ (5ë¶„ ì†Œìš”)
kubectl get certificate -n tiketi
```

#### Day 5: ëª¨ë‹ˆí„°ë§

**2.7 Prometheus & Grafana ì„¤ì¹˜**

```bash
# Helm ì„¤ì¹˜
choco install kubernetes-helm

# Prometheus Stack ì„¤ì¹˜
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --create-namespace

# í™•ì¸
kubectl get pods -n monitoring

# Grafana ì ‘ì†
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80

# ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:3000
# ë¡œê·¸ì¸: admin / prom-operator
```

**2.8 ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­ ì—°ë™**

```javascript
// backend/src/server.jsì— ì´ë¯¸ ìˆëŠ” ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸
app.get('/metrics', async (req, res) => {
  res.set('Content-Type', register.contentType);
  res.end(await register.metrics());
});
```

```yaml
# ServiceMonitor ìƒì„±
cat > k8s/base/servicemonitor.yaml <<EOF
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: backend-metrics
  namespace: tiketi
spec:
  selector:
    matchLabels:
      app: backend
  endpoints:
  - port: http
    path: /metrics
    interval: 30s
EOF

kubectl apply -f k8s/base/servicemonitor.yaml
```

---

## ğŸ¨ 2ë‹¨ê³„: ê²½ëŸ‰ MSA ì „í™˜ (2-3ì£¼)

### Week 3: Payment Service ë¶„ë¦¬

#### ì„œë¹„ìŠ¤ ë¶„ë¦¬ ì „ëµ

```
ê¸°ì¡´ ëª¨ë†€ë¦¬ì‹:
backend/src/routes/
â”œâ”€â”€ auth.js
â”œâ”€â”€ events.js
â”œâ”€â”€ reservations.js
â””â”€â”€ payments.js  â† ì´ê²ƒë§Œ ë¶„ë¦¬

â†“

Core Backend (auth, events, reservations ìœ ì§€)
Payment Service (paymentsë§Œ ë…ë¦½)
```

**3.1 Payment Service ë””ë ‰í† ë¦¬ ìƒì„±**

```bash
mkdir -p services/payment-service/src/{routes,config,services}
cd services/payment-service

npm init -y

npm install express cors dotenv pg axios winston prom-client
npm install --save-dev nodemon
```

**3.2 ê¸°ì¡´ ì½”ë“œ ë³µì‚¬ ë° ìˆ˜ì •**

```bash
# ê¸°ì¡´ íŒŒì¼ ë³µì‚¬
cp ../../backend/src/routes/payments.js src/routes/
cp ../../backend/src/config/database.js src/config/
cp ../../backend/src/utils/logger.js src/utils/

# DB ì„¤ì • ìˆ˜ì • (payments_db ì‚¬ìš©)
# src/config/database.js
```

**3.3 Toss Payments SDK ì¶”ê°€**

```bash
npm install @tosspayments/payment-sdk-node

# src/services/toss-client.js ì‘ì„± (ì´ì „ ê°€ì´ë“œ ì°¸ê³ )
```

**3.4 ì„œë¹„ìŠ¤ ê°„ í†µì‹  í´ë¼ì´ì–¸íŠ¸**

```javascript
// src/clients/core-backend-client.js
const axios = require('axios');

class CoreBackendClient {
  constructor() {
    this.baseURL = process.env.CORE_BACKEND_URL || 'http://backend-service.tiketi.svc.cluster.local';
    this.client = axios.create({
      baseURL: this.baseURL,
      timeout: 5000
    });
  }

  async getReservation(reservationId) {
    const response = await this.client.get(`/api/reservations/${reservationId}`);
    return response.data;
  }

  async confirmReservation(reservationId) {
    const response = await this.client.post(`/api/reservations/${reservationId}/confirm`);
    return response.data;
  }
}

module.exports = new CoreBackendClient();
```

**3.5 Payment Service ë©”ì¸ íŒŒì¼**

```javascript
// src/server.js
const express = require('express');
const cors = require('cors');
const dotenv = require('dotenv');
const paymentRoutes = require('./routes/payments');
const { logger } = require('./utils/logger');

dotenv.config();

const app = express();
const PORT = process.env.PORT || 3002;

app.use(cors());
app.use(express.json());

// Routes
app.use('/api/payments', paymentRoutes);

// Health Check
app.get('/health', (req, res) => {
  res.json({ status: 'UP', service: 'payment-service' });
});

app.listen(PORT, () => {
  logger.info(`ğŸ’³ Payment Service running on port ${PORT}`);
});
```

**3.6 Dockerfile**

```dockerfile
# services/payment-service/Dockerfile
FROM node:20-alpine

WORKDIR /app

COPY package*.json ./
RUN npm ci --only=production

COPY src ./src

EXPOSE 3002

CMD ["node", "src/server.js"]
```

**3.7 K8s ë°°í¬**

```bash
# ì´ë¯¸ì§€ ë¹Œë“œ ë° í‘¸ì‹œ
cd services/payment-service
docker build -t <YOUR_REGISTRY>/payment-service:latest .
docker push <YOUR_REGISTRY>/payment-service:latest

# K8s ë§¤ë‹ˆí˜ìŠ¤íŠ¸
cat > k8s/payment-service.yaml <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: payment-service
  namespace: tiketi
spec:
  replicas: 2
  selector:
    matchLabels:
      app: payment-service
  template:
    metadata:
      labels:
        app: payment-service
    spec:
      containers:
      - name: payment-service
        image: <YOUR_REGISTRY>/payment-service:latest
        ports:
        - containerPort: 3002
        env:
        - name: TOSS_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: TOSS_SECRET_KEY
        - name: CORE_BACKEND_URL
          value: "http://backend-service.tiketi.svc.cluster.local"
---
apiVersion: v1
kind: Service
metadata:
  name: payment-service
  namespace: tiketi
spec:
  selector:
    app: payment-service
  ports:
  - port: 80
    targetPort: 3002
EOF

kubectl apply -f k8s/payment-service.yaml
```

**3.8 Ingress ì—…ë°ì´íŠ¸**

```bash
# k8s/base/ingress.yamlì— ì¶”ê°€
# ...
  - host: api.tiketi.gg
    http:
      paths:
      - path: /api/payments
        pathType: Prefix
        backend:
          service:
            name: payment-service
            port:
              number: 80
      - path: /
        pathType: Prefix
        backend:
          service:
            name: backend-service
            port:
              number: 80

kubectl apply -f k8s/base/ingress.yaml
```

### Week 4: Analytics Service ê°œë°œ

**4.1 Analytics Service ìƒì„±** (ì´ì „ ê°€ì´ë“œ ì°¸ê³ )

- ì´ë²¤íŠ¸ ìˆ˜ì§‘ API
- Redis ì‹¤ì‹œê°„ ì¹´ìš´í„°
- Cron Job ì§‘ê³„
- í†µê³„ ì¡°íšŒ API

**4.2 ë³„ë„ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±**

```bash
# RDSì— analytics_db ìƒì„±
# ë˜ëŠ” K8sì— ë³„ë„ PostgreSQL StatefulSet
```

### Week 5: Google OAuth ì¶”ê°€

**5.1 Core Backendì— Google OAuth ì¶”ê°€**

```bash
cd backend
npm install passport passport-google-oauth20
```

```javascript
// src/config/passport.js ì‘ì„±
// src/routes/auth.jsì— Google ë¼ìš°íŠ¸ ì¶”ê°€
```

---

## ğŸŒŸ 3ë‹¨ê³„: ê³ ê¸‰ ê¸°ëŠ¥ (ì„ íƒ, 2ì£¼)

### Message Queue (RabbitMQ)

```bash
# RabbitMQ ì„¤ì¹˜
helm install rabbitmq bitnami/rabbitmq --namespace tiketi

# Payment Serviceì—ì„œ ì´ë²¤íŠ¸ ë°œí–‰
await messageQueue.publish('payment.completed', {
  reservationId,
  amount
});

# Analytics Serviceì—ì„œ êµ¬ë…
messageQueue.subscribe('payment.completed', async (data) => {
  await updateStats(data);
});
```

---

## âœ… ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

### 1ë‹¨ê³„ ì™„ë£Œ ì‹œ
- [ ] EKS í´ëŸ¬ìŠ¤í„° ìƒì„±
- [ ] Frontend, Backend, DB, Redis ë°°í¬
- [ ] Ingress ì„¤ì •
- [ ] SSL ì¸ì¦ì„œ ë°œê¸‰
- [ ] ëª¨ë‹ˆí„°ë§ (Prometheus, Grafana)
- [ ] **ë™ì‘ í™•ì¸**: https://tiketi.gg ì ‘ì†

### 2ë‹¨ê³„ ì™„ë£Œ ì‹œ
- [ ] Payment Service ë¶„ë¦¬
- [ ] Analytics Service ê°œë°œ
- [ ] Google OAuth ì¶”ê°€
- [ ] ì„œë¹„ìŠ¤ ê°„ í†µì‹  í™•ì¸

### 3ë‹¨ê³„ ì™„ë£Œ ì‹œ (ì„ íƒ)
- [ ] Message Queue ì¶”ê°€
- [ ] Circuit Breaker êµ¬í˜„
- [ ] Distributed Tracing

---

## ğŸ“Š í•™ìŠµ íš¨ê³¼

| ë‹¨ê³„ | ë°°ìš¸ ìˆ˜ ìˆëŠ” ê²ƒ | í¬íŠ¸í´ë¦¬ì˜¤ ê°•ì  |
|------|----------------|----------------|
| 1ë‹¨ê³„ | K8s í•µì‹¬ ê°œë… | "K8s ë°°í¬ ê²½í—˜" |
| 2ë‹¨ê³„ | MSA íŒ¨í„´ | "MSA ì•„í‚¤í…ì²˜ ì„¤ê³„" |
| 3ë‹¨ê³„ | ê³ ê¸‰ íŒ¨í„´ | "ë¶„ì‚° ì‹œìŠ¤í…œ ê²½í—˜" |

---

## ğŸ’° ì˜ˆìƒ ë¹„ìš©

- **EKS í´ëŸ¬ìŠ¤í„°**: $73/ì›”
- **EC2 ë…¸ë“œ (t3.medium Ã— 2)**: $60/ì›”
- **RDS (ì„ íƒ)**: $80/ì›”
- **ê¸°íƒ€**: $20/ì›”

**ì´**: $233/ì›” (â‚©303,000/ì›”)

**ë¹„ìš© ì ˆê°**:
- RDS ëŒ€ì‹  K8s StatefulSet ì‚¬ìš© â†’ $150/ì›” ì ˆì•½
- Spot Instance ì‚¬ìš© â†’ ì¶”ê°€ 50% ì ˆì•½

---

**ì‘ì„±ì¼**: 2025-12-05
**ì‘ì„±ì**: Claude
