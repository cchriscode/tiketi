# K8s MSA ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤ì „ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ì´ ê°€ì´ë“œëŠ” í˜„ì¬ Tiketi ëª¨ë†€ë¦¬ì‹ ë°±ì—”ë“œë¥¼ K8s ê¸°ë°˜ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ë¡œ ì „í™˜í•˜ëŠ” **ì‹¤ì œ ì‘ì—… ìˆœì„œ**ë¥¼ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.

**í˜„ì¬ ìƒíƒœ (AS-IS)**:
- ë‹¨ì¼ Node.js ë°±ì—”ë“œ (`backend/src/`)
- ë‹¨ì¼ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤
- ë‹¨ì¼ Redis ì¸ìŠ¤í„´ìŠ¤
- Docker Compose ë°°í¬

**ëª©í‘œ ìƒíƒœ (TO-BE)**:
- 8ê°œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤
- ì„œë¹„ìŠ¤ë³„ ë…ë¦½ ë°ì´í„°ë² ì´ìŠ¤
- K8s í´ëŸ¬ìŠ¤í„° ë°°í¬
- CI/CD ìë™í™”

---

## ğŸ¯ ì „ì²´ ë¡œë“œë§µ (10ì£¼)

```
Phase 1: ì¤€ë¹„ ë° ì¸í”„ë¼ (Week 1-2)
â”œâ”€ Week 1: AWS ì¸í”„ë¼ êµ¬ì¶•
â””â”€ Week 2: ë°ì´í„°ë² ì´ìŠ¤ ë¶„ë¦¬ ê³„íš

Phase 2: ì½”ì–´ ì„œë¹„ìŠ¤ ë¶„ë¦¬ (Week 3-5)
â”œâ”€ Week 3: User Service, Event Service
â”œâ”€ Week 4: Reservation Service, Payment Service
â””â”€ Week 5: Queue Service, Media Service

Phase 3: ì‹ ê·œ ê¸°ëŠ¥ ê°œë°œ (Week 6-7)
â”œâ”€ Week 6: Analytics Service, Google OAuth
â””â”€ Week 7: Toss Payments í†µí•©

Phase 4: í†µí•© ë° ë°°í¬ (Week 8-10)
â”œâ”€ Week 8: Admin Service, CI/CD
â”œâ”€ Week 9: í†µí•© í…ŒìŠ¤íŠ¸, ì„±ëŠ¥ ìµœì í™”
â””â”€ Week 10: í”„ë¡œë•ì…˜ ë°°í¬
```

---

## ğŸ“‚ í˜„ì¬ í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„

### ë°±ì—”ë“œ ì½”ë“œ êµ¬ì¡°

```
backend/src/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ database.js          # PostgreSQL ì—°ê²°
â”‚   â”œâ”€â”€ redis.js             # Redis ì—°ê²°
â”‚   â”œâ”€â”€ socket.js            # Socket.IO ì„¤ì •
â”‚   â”œâ”€â”€ swagger.js           # API ë¬¸ì„œ
â”‚   â”œâ”€â”€ init-admin.js        # ê´€ë¦¬ì ê³„ì • ì´ˆê¸°í™”
â”‚   â””â”€â”€ init-seats.js        # ì¢Œì„ ì´ˆê¸°í™”
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ auth.js              # ë¡œê·¸ì¸/íšŒì›ê°€ì…
â”‚   â”œâ”€â”€ events.js            # ì´ë²¤íŠ¸ CRUD
â”‚   â”œâ”€â”€ reservations.js      # ì˜ˆì•½ ê´€ë¦¬
â”‚   â”œâ”€â”€ seats.js             # ì¢Œì„ ì¡°íšŒ
â”‚   â”œâ”€â”€ tickets.js           # í‹°ì¼“ ì¡°íšŒ
â”‚   â”œâ”€â”€ payments.js          # ê²°ì œ ì²˜ë¦¬
â”‚   â”œâ”€â”€ admin.js             # ê´€ë¦¬ì ê¸°ëŠ¥
â”‚   â”œâ”€â”€ queue.js             # ëŒ€ê¸°ì—´ API
â”‚   â”œâ”€â”€ news.js              # ë‰´ìŠ¤ ê´€ë¦¬
â”‚   â”œâ”€â”€ image.js             # ì´ë¯¸ì§€ ì—…ë¡œë“œ
â”‚   â””â”€â”€ health.js            # í—¬ìŠ¤ì²´í¬
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ reservation-cleaner.js    # ì˜ˆì•½ íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
â”‚   â”œâ”€â”€ event-status-updater.js   # ì´ë²¤íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸
â”‚   â”œâ”€â”€ queue-manager.js          # ëŒ€ê¸°ì—´ ê´€ë¦¬
â”‚   â”œâ”€â”€ seat-generator.js         # ì¢Œì„ ìƒì„±
â”‚   â””â”€â”€ socket-session-manager.js # ì†Œì¼“ ì„¸ì…˜ ê´€ë¦¬
â”œâ”€â”€ middleware/
â”‚   â”œâ”€â”€ auth.js              # JWT ì¸ì¦
â”‚   â”œâ”€â”€ error-handler.js     # ì—ëŸ¬ í•¸ë“¤ë§
â”‚   â””â”€â”€ request-logger.js    # ìš”ì²­ ë¡œê¹…
â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ index.js             # Prometheus ë©”íŠ¸ë¦­
â”‚   â”œâ”€â”€ middleware.js        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë¯¸ë“¤ì›¨ì–´
â”‚   â”œâ”€â”€ aggregator.js        # ë©”íŠ¸ë¦­ ì§‘ê³„
â”‚   â””â”€â”€ db.js                # DB ë©”íŠ¸ë¦­
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ logger.js            # Winston ë¡œê±°
â”‚   â”œâ”€â”€ custom-error.js      # ì»¤ìŠ¤í…€ ì—ëŸ¬
â”‚   â”œâ”€â”€ transaction-helpers.js  # íŠ¸ëœì­ì…˜ í—¬í¼
â”‚   â””â”€â”€ header-info-extractor.js
â”œâ”€â”€ shared/
â”‚   â””â”€â”€ constants.js         # ìƒìˆ˜ ì •ì˜
â””â”€â”€ server.js                # ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
```

### ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

```sql
í•µì‹¬ í…Œì´ë¸”:
- users                    # ì‚¬ìš©ì
- events                   # ì´ë²¤íŠ¸
- seat_layouts             # ì¢Œì„ ë ˆì´ì•„ì›ƒ
- seats                    # ê°œë³„ ì¢Œì„
- ticket_types             # í‹°ì¼“ íƒ€ì…
- reservations             # ì˜ˆì•½
- reservation_items        # ì˜ˆì•½ ì•„ì´í…œ
- news                     # ë‰´ìŠ¤
- keyword_mappings         # í‚¤ì›Œë“œ ë§¤í•‘
```

---

## ğŸš€ Phase 1: ì¤€ë¹„ ë° ì¸í”„ë¼ (Week 1-2)

### Week 1: AWS ì¸í”„ë¼ êµ¬ì¶•

#### Day 1-2: VPC ë° EKS í´ëŸ¬ìŠ¤í„° ìƒì„±

**1.1 VPC ìƒì„±**

```bash
# AWS CLIë¥¼ ì‚¬ìš©í•œ VPC ìƒì„±
aws ec2 create-vpc \
  --cidr-block 10.0.0.0/16 \
  --tag-specifications 'ResourceType=vpc,Tags=[{Key=Name,Value=tiketi-vpc}]'

# Subnet ìƒì„±
# Public Subnet A (ap-northeast-2a)
aws ec2 create-subnet \
  --vpc-id <VPC_ID> \
  --cidr-block 10.0.1.0/24 \
  --availability-zone ap-northeast-2a \
  --tag-specifications 'ResourceType=subnet,Tags=[{Key=Name,Value=tiketi-public-a}]'

# Public Subnet C (ap-northeast-2c)
aws ec2 create-subnet \
  --vpc-id <VPC_ID> \
  --cidr-block 10.0.2.0/24 \
  --availability-zone ap-northeast-2c \
  --tag-specifications 'ResourceType=subnet,Tags=[{Key=Name,Value=tiketi-public-c}]'

# Private Subnet A
aws ec2 create-subnet \
  --vpc-id <VPC_ID> \
  --cidr-block 10.0.10.0/24 \
  --availability-zone ap-northeast-2a \
  --tag-specifications 'ResourceType=subnet,Tags=[{Key=Name,Value=tiketi-private-a}]'

# Private Subnet C
aws ec2 create-subnet \
  --vpc-id <VPC_ID> \
  --cidr-block 10.0.11.0/24 \
  --availability-zone ap-northeast-2c \
  --tag-specifications 'ResourceType=subnet,Tags=[{Key=Name,Value=tiketi-private-c}]'

# Internet Gateway ìƒì„± ë° ì—°ê²°
aws ec2 create-internet-gateway \
  --tag-specifications 'ResourceType=internet-gateway,Tags=[{Key=Name,Value=tiketi-igw}]'

aws ec2 attach-internet-gateway \
  --internet-gateway-id <IGW_ID> \
  --vpc-id <VPC_ID>

# NAT Gateway ìƒì„± (Public Subnet Aì—)
aws ec2 allocate-address --domain vpc  # EIP í• ë‹¹
aws ec2 create-nat-gateway \
  --subnet-id <PUBLIC_SUBNET_A_ID> \
  --allocation-id <EIP_ALLOCATION_ID> \
  --tag-specifications 'ResourceType=nat-gateway,Tags=[{Key=Name,Value=tiketi-nat-a}]'
```

**1.2 EKS í´ëŸ¬ìŠ¤í„° ìƒì„±**

```bash
# eksctl ì„¤ì¹˜ (Windows - PowerShell)
choco install eksctl

# eksctlì„ ì‚¬ìš©í•œ í´ëŸ¬ìŠ¤í„° ìƒì„±
eksctl create cluster \
  --name tiketi-prod \
  --region ap-northeast-2 \
  --vpc-public-subnets <PUBLIC_SUBNET_IDS> \
  --vpc-private-subnets <PRIVATE_SUBNET_IDS> \
  --without-nodegroup

# kubectl ì„¤ì •
aws eks update-kubeconfig --region ap-northeast-2 --name tiketi-prod

# í´ëŸ¬ìŠ¤í„° í™•ì¸
kubectl get nodes
kubectl get namespaces
```

**1.3 ë…¸ë“œ ê·¸ë£¹ ìƒì„±**

```bash
# Application Node Group
eksctl create nodegroup \
  --cluster tiketi-prod \
  --name tiketi-app-nodes \
  --node-type t3.medium \
  --nodes 3 \
  --nodes-min 2 \
  --nodes-max 10 \
  --node-private-networking \
  --ssh-access \
  --ssh-public-key <YOUR_KEY_NAME>

# Stateful Node Group
eksctl create nodegroup \
  --cluster tiketi-prod \
  --name tiketi-stateful-nodes \
  --node-type t3.small \
  --nodes 2 \
  --nodes-min 2 \
  --nodes-max 5 \
  --node-private-networking

# Data Node Group
eksctl create nodegroup \
  --cluster tiketi-prod \
  --name tiketi-data-nodes \
  --node-type t3.medium \
  --nodes 2 \
  --nodes-min 2 \
  --nodes-max 4 \
  --node-private-networking

# System Node Group
eksctl create nodegroup \
  --cluster tiketi-prod \
  --name tiketi-system-nodes \
  --node-type t3.small \
  --nodes 2 \
  --nodes-min 2 \
  --nodes-max 3 \
  --node-private-networking
```

#### Day 3-4: ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë° ê¸°ë³¸ ì„¤ì •

**1.4 ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±**

```bash
# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
mkdir -p k8s/namespaces
cat > k8s/namespaces/namespaces.yaml <<EOF
apiVersion: v1
kind: Namespace
metadata:
  name: tiketi-production
---
apiVersion: v1
kind: Namespace
metadata:
  name: tiketi-data
---
apiVersion: v1
kind: Namespace
metadata:
  name: tiketi-monitoring
---
apiVersion: v1
kind: Namespace
metadata:
  name: tiketi-system
EOF

# ì ìš©
kubectl apply -f k8s/namespaces/namespaces.yaml

# í™•ì¸
kubectl get namespaces
```

**1.5 Ingress Controller ì„¤ì¹˜**

```bash
# NGINX Ingress Controller ì„¤ì¹˜
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.1/deploy/static/provider/aws/deploy.yaml

# í™•ì¸
kubectl get pods -n ingress-nginx
kubectl get svc -n ingress-nginx
```

**1.6 Cert-Manager ì„¤ì¹˜ (SSL ì¸ì¦ì„œ)**

```bash
# Cert-Manager ì„¤ì¹˜
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.0/cert-manager.yaml

# ClusterIssuer ìƒì„± (Let's Encrypt)
cat > k8s/cert-manager/cluster-issuer.yaml <<EOF
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: admin@tiketi.gg
    privateKeySecretRef:
      name: letsencrypt-prod
    solvers:
    - http01:
        ingress:
          class: nginx
EOF

kubectl apply -f k8s/cert-manager/cluster-issuer.yaml
```

#### Day 5: RDS ë° ElastiCache ìƒì„±

**1.7 RDS PostgreSQL ìƒì„±**

```bash
# RDS Subnet Group ìƒì„±
aws rds create-db-subnet-group \
  --db-subnet-group-name tiketi-db-subnet \
  --db-subnet-group-description "Tiketi DB Subnet Group" \
  --subnet-ids <PRIVATE_SUBNET_A_ID> <PRIVATE_SUBNET_C_ID>

# Security Group ìƒì„±
aws ec2 create-security-group \
  --group-name tiketi-rds-sg \
  --description "Tiketi RDS Security Group" \
  --vpc-id <VPC_ID>

# Ingress ê·œì¹™ ì¶”ê°€ (EKS ë…¸ë“œì—ì„œë§Œ ì ‘ê·¼ í—ˆìš©)
aws ec2 authorize-security-group-ingress \
  --group-id <RDS_SG_ID> \
  --protocol tcp \
  --port 5432 \
  --source-group <EKS_NODE_SG_ID>

# RDS ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
aws rds create-db-instance \
  --db-instance-identifier tiketi-prod-db \
  --db-instance-class db.t3.medium \
  --engine postgres \
  --engine-version 15.4 \
  --master-username tiketi_admin \
  --master-user-password <STRONG_PASSWORD> \
  --allocated-storage 20 \
  --storage-type gp3 \
  --db-subnet-group-name tiketi-db-subnet \
  --vpc-security-group-ids <RDS_SG_ID> \
  --multi-az \
  --backup-retention-period 7 \
  --preferred-backup-window "03:00-04:00" \
  --preferred-maintenance-window "Mon:04:00-Mon:05:00" \
  --no-publicly-accessible

# ìƒì„± í™•ì¸ (5-10ë¶„ ì†Œìš”)
aws rds describe-db-instances --db-instance-identifier tiketi-prod-db
```

**1.8 ElastiCache Redis ìƒì„±**

```bash
# ElastiCache Subnet Group ìƒì„±
aws elasticache create-cache-subnet-group \
  --cache-subnet-group-name tiketi-redis-subnet \
  --cache-subnet-group-description "Tiketi Redis Subnet Group" \
  --subnet-ids <PRIVATE_SUBNET_A_ID> <PRIVATE_SUBNET_C_ID>

# Security Group ìƒì„±
aws ec2 create-security-group \
  --group-name tiketi-redis-sg \
  --description "Tiketi Redis Security Group" \
  --vpc-id <VPC_ID>

# Ingress ê·œì¹™
aws ec2 authorize-security-group-ingress \
  --group-id <REDIS_SG_ID> \
  --protocol tcp \
  --port 6379 \
  --source-group <EKS_NODE_SG_ID>

# Redis Cluster ìƒì„±
aws elasticache create-replication-group \
  --replication-group-id tiketi-redis-cluster \
  --replication-group-description "Tiketi Redis Cluster" \
  --engine redis \
  --cache-node-type cache.t3.micro \
  --num-cache-clusters 3 \
  --cache-subnet-group-name tiketi-redis-subnet \
  --security-group-ids <REDIS_SG_ID> \
  --automatic-failover-enabled \
  --multi-az-enabled

# ìƒì„± í™•ì¸
aws elasticache describe-replication-groups \
  --replication-group-id tiketi-redis-cluster
```

### Week 2: ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤€ë¹„

#### Day 1-2: ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë¶„ë¦¬ ê³„íš

**2.1 ì„œë¹„ìŠ¤ë³„ ë°ì´í„°ë² ì´ìŠ¤ ë¶„ë¦¬ ë§¤í•‘**

í˜„ì¬ í…Œì´ë¸”ì„ ì„œë¹„ìŠ¤ë³„ë¡œ ë¶„ë¦¬:

```
User Service (users_db):
- users
- oauth_providers (ì‹ ê·œ)

Event Service (events_db):
- events
- seat_layouts
- ticket_types
- keyword_mappings

Reservation Service (reservations_db):
- reservations
- reservation_items
- seats

Payment Service (payments_db):
- payments (ì‹ ê·œ)
- refunds (ì‹ ê·œ)

Analytics Service (analytics_db):
- analytics_events (ì‹ ê·œ)
- daily_stats (ì‹ ê·œ)
- artist_traffic (ì‹ ê·œ)
- revenue_stats (ì‹ ê·œ)

Admin Service (admin_db):
- news
- admin_logs (ì‹ ê·œ)
```

**2.2 ë°ì´í„°ë² ì´ìŠ¤ ë¶„ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±**

```bash
# ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p database/migrations-msa
```

```sql
-- database/migrations-msa/01_create_service_databases.sql

-- User Service Database
CREATE DATABASE users_db;

-- Event Service Database
CREATE DATABASE events_db;

-- Reservation Service Database
CREATE DATABASE reservations_db;

-- Payment Service Database
CREATE DATABASE payments_db;

-- Analytics Service Database
CREATE DATABASE analytics_db;

-- Admin Service Database
CREATE DATABASE admin_db;
```

**2.3 ê° ì„œë¹„ìŠ¤ë³„ ìŠ¤í‚¤ë§ˆ íŒŒì¼ ì‘ì„±**

```bash
# User Service Schema
cat > database/migrations-msa/users_db_schema.sql <<EOF
-- Connect to users_db
\c users_db

-- Enable extensions
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Users table
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    name VARCHAR(100) NOT NULL,
    phone VARCHAR(20),
    role VARCHAR(20) DEFAULT 'user' CHECK (role IN ('user', 'admin')),
    email_verified BOOLEAN DEFAULT FALSE,
    profile_image VARCHAR(255),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- OAuth Providers table (NEW for Google Login)
CREATE TABLE oauth_providers (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    provider VARCHAR(50) NOT NULL, -- 'google', 'kakao', 'naver'
    provider_user_id VARCHAR(255) NOT NULL,
    access_token TEXT,
    refresh_token TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(provider, provider_user_id)
);

-- Indexes
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_oauth_providers_user_id ON oauth_providers(user_id);
CREATE INDEX idx_oauth_providers_provider ON oauth_providers(provider, provider_user_id);

-- Triggers
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS \$\$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
\$\$ LANGUAGE plpgsql;

CREATE TRIGGER update_users_updated_at BEFORE UPDATE ON users
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_oauth_providers_updated_at BEFORE UPDATE ON oauth_providers
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
EOF
```

```bash
# Payment Service Schema
cat > database/migrations-msa/payments_db_schema.sql <<EOF
-- Connect to payments_db
\c payments_db

CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Payments table (NEW for Toss Payments)
CREATE TABLE payments (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    reservation_id UUID NOT NULL, -- Foreign keyëŠ” ë…¼ë¦¬ì ìœ¼ë¡œë§Œ ì—°ê²°
    user_id UUID NOT NULL,
    amount INTEGER NOT NULL,
    status VARCHAR(20) DEFAULT 'PENDING' CHECK (status IN ('PENDING', 'COMPLETED', 'FAILED', 'CANCELLED')),
    provider VARCHAR(50) NOT NULL DEFAULT 'TOSS', -- 'TOSS', 'CARD', etc
    payment_key VARCHAR(255), -- Toss Payment Key
    order_id VARCHAR(255) UNIQUE,
    approved_at TIMESTAMP,
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Refunds table (NEW)
CREATE TABLE refunds (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    payment_id UUID REFERENCES payments(id) ON DELETE CASCADE,
    amount INTEGER NOT NULL,
    reason VARCHAR(255),
    status VARCHAR(20) DEFAULT 'PENDING' CHECK (status IN ('PENDING', 'COMPLETED', 'FAILED')),
    refunded_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Indexes
CREATE INDEX idx_payments_reservation_id ON payments(reservation_id);
CREATE INDEX idx_payments_user_id ON payments(user_id);
CREATE INDEX idx_payments_status ON payments(status);
CREATE INDEX idx_payments_order_id ON payments(order_id);
CREATE INDEX idx_refunds_payment_id ON refunds(payment_id);
EOF
```

```bash
# Analytics Service Schema
cat > database/migrations-msa/analytics_db_schema.sql <<EOF
-- Connect to analytics_db
\c analytics_db

CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Enable TimescaleDB extension (if using TimescaleDB)
-- CREATE EXTENSION IF NOT EXISTS timescaledb;

-- Analytics Events table (Event Store)
CREATE TABLE analytics_events (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    event_type VARCHAR(100) NOT NULL, -- 'page_view', 'payment_completed', etc
    aggregate_id VARCHAR(255) NOT NULL, -- artist_id, event_id, etc
    data JSONB NOT NULL,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Daily Stats table (Aggregated)
CREATE TABLE daily_stats (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    date DATE NOT NULL,
    artist_id UUID,
    event_id UUID,
    page_views INTEGER DEFAULT 0,
    unique_visitors INTEGER DEFAULT 0,
    reservations_count INTEGER DEFAULT 0,
    revenue INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(date, artist_id, event_id)
);

-- Artist Traffic table (NEW for Admin Dashboard)
CREATE TABLE artist_traffic (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    artist_id UUID NOT NULL,
    artist_name VARCHAR(255),
    date DATE NOT NULL,
    page_views INTEGER DEFAULT 0,
    unique_visitors INTEGER DEFAULT 0,
    avg_session_duration INTEGER DEFAULT 0, -- seconds
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(artist_id, date)
);

-- Revenue Stats table (NEW for Admin Dashboard)
CREATE TABLE revenue_stats (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    period_type VARCHAR(20) NOT NULL CHECK (period_type IN ('daily', 'weekly', 'monthly')),
    period_start DATE NOT NULL,
    total_revenue INTEGER DEFAULT 0,
    tickets_sold INTEGER DEFAULT 0,
    avg_ticket_price INTEGER DEFAULT 0,
    top_artist_id UUID,
    top_artist_revenue INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(period_type, period_start)
);

-- Indexes
CREATE INDEX idx_analytics_events_type ON analytics_events(event_type);
CREATE INDEX idx_analytics_events_timestamp ON analytics_events(timestamp DESC);
CREATE INDEX idx_daily_stats_date ON daily_stats(date DESC);
CREATE INDEX idx_daily_stats_artist ON daily_stats(artist_id, date DESC);
CREATE INDEX idx_artist_traffic_date ON artist_traffic(date DESC);
CREATE INDEX idx_artist_traffic_artist ON artist_traffic(artist_id, date DESC);
CREATE INDEX idx_revenue_stats_period ON revenue_stats(period_type, period_start DESC);

-- Convert to hypertable (if using TimescaleDB)
-- SELECT create_hypertable('analytics_events', 'timestamp');
-- SELECT create_hypertable('daily_stats', 'date');
EOF
```

#### Day 3-4: ê¸°ì¡´ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

**2.4 ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸**

```bash
# ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
cat > database/migrations-msa/migrate_data.sql <<EOF
-- ===============================================
-- Data Migration Script: Monolith â†’ MSA
-- ===============================================

-- Step 1: Migrate Users
INSERT INTO users_db.users
SELECT * FROM tiketi.users;

-- Step 2: Migrate Events
INSERT INTO events_db.events
SELECT * FROM tiketi.events;

INSERT INTO events_db.seat_layouts
SELECT * FROM tiketi.seat_layouts;

INSERT INTO events_db.ticket_types
SELECT * FROM tiketi.ticket_types;

INSERT INTO events_db.keyword_mappings
SELECT * FROM tiketi.keyword_mappings;

-- Step 3: Migrate Reservations
INSERT INTO reservations_db.reservations
SELECT * FROM tiketi.reservations;

INSERT INTO reservations_db.reservation_items
SELECT * FROM tiketi.reservation_items;

INSERT INTO reservations_db.seats
SELECT * FROM tiketi.seats;

-- Step 4: Admin Data
INSERT INTO admin_db.news
SELECT * FROM tiketi.news;

-- Note: Payments and Analytics are new tables (no migration needed)
EOF
```

#### Day 5: ConfigMap & Secrets ì¤€ë¹„

**2.5 K8s ConfigMap ì‘ì„±**

```bash
mkdir -p k8s/config
cat > k8s/config/configmap.yaml <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: tiketi-production
data:
  NODE_ENV: "production"
  LOG_LEVEL: "info"
  CORS_ORIGIN: "https://tiketi.gg"

  # Database Hosts (RDS Endpoints)
  USERS_DB_HOST: "<RDS_ENDPOINT>"
  EVENTS_DB_HOST: "<RDS_ENDPOINT>"
  RESERVATIONS_DB_HOST: "<RDS_ENDPOINT>"
  PAYMENTS_DB_HOST: "<RDS_ENDPOINT>"
  ANALYTICS_DB_HOST: "<RDS_ENDPOINT>"
  ADMIN_DB_HOST: "<RDS_ENDPOINT>"

  # Database Names
  USERS_DB_NAME: "users_db"
  EVENTS_DB_NAME: "events_db"
  RESERVATIONS_DB_NAME: "reservations_db"
  PAYMENTS_DB_NAME: "payments_db"
  ANALYTICS_DB_NAME: "analytics_db"
  ADMIN_DB_NAME: "admin_db"

  # Redis
  REDIS_HOST: "<ELASTICACHE_ENDPOINT>"
  REDIS_PORT: "6379"

  # AWS S3
  S3_BUCKET: "tiketi-media-prod"
  S3_REGION: "ap-northeast-2"

  # Service URLs (Internal)
  USER_SERVICE_URL: "http://user-service.tiketi-production.svc.cluster.local"
  EVENT_SERVICE_URL: "http://event-service.tiketi-production.svc.cluster.local"
  RESERVATION_SERVICE_URL: "http://reservation-service.tiketi-production.svc.cluster.local"
  PAYMENT_SERVICE_URL: "http://payment-service.tiketi-production.svc.cluster.local"
  ANALYTICS_SERVICE_URL: "http://analytics-service.tiketi-production.svc.cluster.local"
EOF
```

**2.6 K8s Secrets ì‘ì„±**

```bash
# Secretsë¥¼ base64 ì¸ì½”ë”©
cat > k8s/config/secrets.yaml <<EOF
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: tiketi-production
type: Opaque
stringData:
  # Database
  DB_USER: "tiketi_admin"
  DB_PASSWORD: "<YOUR_DB_PASSWORD>"

  # JWT
  JWT_SECRET: "<YOUR_JWT_SECRET>"

  # Redis (if password enabled)
  REDIS_PASSWORD: ""

  # Toss Payments
  TOSS_SECRET_KEY: "<YOUR_TOSS_SECRET_KEY>"
  TOSS_CLIENT_KEY: "<YOUR_TOSS_CLIENT_KEY>"

  # Google OAuth
  GOOGLE_CLIENT_ID: "<YOUR_GOOGLE_CLIENT_ID>"
  GOOGLE_CLIENT_SECRET: "<YOUR_GOOGLE_CLIENT_SECRET>"

  # AWS Credentials
  AWS_ACCESS_KEY_ID: "<YOUR_AWS_ACCESS_KEY>"
  AWS_SECRET_ACCESS_KEY: "<YOUR_AWS_SECRET_KEY>"
EOF

# ì ìš©
kubectl apply -f k8s/config/configmap.yaml
kubectl apply -f k8s/config/secrets.yaml
```

---

## ğŸ”§ Phase 2: ì½”ì–´ ì„œë¹„ìŠ¤ ë¶„ë¦¬ (Week 3-5)

### Week 3: User Service & Event Service

#### User Service ë¶„ë¦¬

**Step 1: ì„œë¹„ìŠ¤ ë””ë ‰í† ë¦¬ ìƒì„±**

```bash
mkdir -p services/user-service
cd services/user-service

# í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
npm init -y

# ì˜ì¡´ì„± ì„¤ì¹˜
npm install express cors dotenv pg bcrypt jsonwebtoken express-validator passport passport-google-oauth20 winston prom-client
npm install --save-dev nodemon
```

**Step 2: ì½”ë“œ ë³µì‚¬ ë° ìˆ˜ì •**

```bash
# ê¸°ë³¸ êµ¬ì¡° ìƒì„±
mkdir -p src/{routes,config,middleware,utils}

# ê¸°ì¡´ ì½”ë“œì—ì„œ í•„ìš”í•œ íŒŒì¼ ë³µì‚¬
cp ../../backend/src/routes/auth.js src/routes/
cp ../../backend/src/config/database.js src/config/
cp ../../backend/src/middleware/auth.js src/middleware/
cp ../../backend/src/utils/logger.js src/utils/
cp ../../backend/src/utils/custom-error.js src/utils/
cp ../../backend/src/shared/constants.js src/shared/
```

**Step 3: User Service ë©”ì¸ íŒŒì¼ ì‘ì„±**

```javascript
// services/user-service/src/server.js
const express = require('express');
const cors = require('cors');
const dotenv = require('dotenv');
const passport = require('passport');
const { logger } = require('./utils/logger');
const authRoutes = require('./routes/auth');
const errorHandler = require('./middleware/error-handler');
require('./config/passport'); // Google OAuth ì„¤ì •

dotenv.config();

const app = express();
const PORT = process.env.PORT || 3001;

// Middleware
app.use(cors());
app.use(express.json());
app.use(passport.initialize());

// Routes
app.use('/api/users', authRoutes);

// Health Check
app.get('/health', (req, res) => {
  res.json({ status: 'UP', service: 'user-service' });
});

app.get('/ready', (req, res) => {
  // DB ì—°ê²° í™•ì¸
  res.json({ status: 'READY' });
});

// Prometheus metrics
app.get('/metrics', async (req, res) => {
  const { register } = require('./metrics');
  res.set('Content-Type', register.contentType);
  res.end(await register.metrics());
});

// Error handling
app.use(errorHandler);

app.listen(PORT, () => {
  logger.info(`ğŸš€ User Service running on port ${PORT}`);
});
```

**Step 4: Google OAuth ì„¤ì •**

```javascript
// services/user-service/src/config/passport.js
const passport = require('passport');
const GoogleStrategy = require('passport-google-oauth20').Strategy;
const db = require('./database');

passport.use(new GoogleStrategy({
  clientID: process.env.GOOGLE_CLIENT_ID,
  clientSecret: process.env.GOOGLE_CLIENT_SECRET,
  callbackURL: '/api/users/google/callback'
}, async (accessToken, refreshToken, profile, done) => {
  try {
    // ê¸°ì¡´ ì‚¬ìš©ì í™•ì¸
    let userResult = await db.query(`
      SELECT u.* FROM users u
      JOIN oauth_providers op ON u.id = op.user_id
      WHERE op.provider = 'google' AND op.provider_user_id = $1
    `, [profile.id]);

    let user;

    if (userResult.rows.length === 0) {
      // ì‹ ê·œ ì‚¬ìš©ì ìƒì„±
      const newUser = await db.query(`
        INSERT INTO users (email, name, email_verified, profile_image)
        VALUES ($1, $2, true, $3)
        RETURNING *
      `, [
        profile.emails[0].value,
        profile.displayName,
        profile.photos[0]?.value
      ]);

      user = newUser.rows[0];

      // OAuth ì—°ê²° ì •ë³´ ì €ì¥
      await db.query(`
        INSERT INTO oauth_providers (user_id, provider, provider_user_id, access_token)
        VALUES ($1, 'google', $2, $3)
      `, [user.id, profile.id, accessToken]);
    } else {
      user = userResult.rows[0];

      // í† í° ì—…ë°ì´íŠ¸
      await db.query(`
        UPDATE oauth_providers
        SET access_token = $1, updated_at = NOW()
        WHERE user_id = $2 AND provider = 'google'
      `, [accessToken, user.id]);
    }

    return done(null, user);
  } catch (error) {
    return done(error);
  }
}));
```

**Step 5: ë¼ìš°íŠ¸ ì—…ë°ì´íŠ¸ (Google Login ì¶”ê°€)**

```javascript
// services/user-service/src/routes/auth.js
const express = require('express');
const passport = require('passport');
const jwt = require('jsonwebtoken');
const router = express.Router();

// ê¸°ì¡´ /register, /login ë¼ìš°íŠ¸ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€...

// Google Login
router.get('/google',
  passport.authenticate('google', {
    scope: ['profile', 'email']
  })
);

// Google Callback
router.get('/google/callback',
  passport.authenticate('google', { session: false }),
  (req, res) => {
    // JWT í† í° ë°œê¸‰
    const token = jwt.sign(
      { userId: req.user.id, email: req.user.email, role: req.user.role },
      process.env.JWT_SECRET,
      { expiresIn: '7d' }
    );

    // í”„ë¡ íŠ¸ì—”ë“œë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
    res.redirect(`${process.env.FRONTEND_URL}/auth/callback?token=${token}`);
  }
);

module.exports = router;
```

**Step 6: Dockerfile ì‘ì„±**

```dockerfile
# services/user-service/Dockerfile
FROM node:20-alpine

WORKDIR /app

# ì˜ì¡´ì„± ì„¤ì¹˜
COPY package*.json ./
RUN npm ci --only=production

# ì†ŒìŠ¤ ë³µì‚¬
COPY src ./src

# í—¬ìŠ¤ì²´í¬
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node -e "require('http').get('http://localhost:3001/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"

EXPOSE 3001

CMD ["node", "src/server.js"]
```

**Step 7: K8s ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì‘ì„±**

```yaml
# services/user-service/k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
  namespace: tiketi-production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: user-service
  template:
    metadata:
      labels:
        app: user-service
        version: v1
    spec:
      containers:
      - name: user-service
        image: <AWS_ACCOUNT_ID>.dkr.ecr.ap-northeast-2.amazonaws.com/user-service:latest
        ports:
        - containerPort: 3001
        env:
        - name: PORT
          value: "3001"
        - name: DB_HOST
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: USERS_DB_HOST
        - name: DB_NAME
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: USERS_DB_NAME
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: DB_USER
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: DB_PASSWORD
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: JWT_SECRET
        - name: GOOGLE_CLIENT_ID
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: GOOGLE_CLIENT_ID
        - name: GOOGLE_CLIENT_SECRET
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: GOOGLE_CLIENT_SECRET
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 3001
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 3001
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: user-service
  namespace: tiketi-production
spec:
  selector:
    app: user-service
  ports:
  - protocol: TCP
    port: 80
    targetPort: 3001
  type: ClusterIP
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: user-service-hpa
  namespace: tiketi-production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: user-service
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

**Step 8: ë¹Œë“œ ë° ë°°í¬**

```bash
# ECRì— í‘¸ì‹œ
aws ecr create-repository --repository-name user-service

# Docker ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t user-service:latest .

# ECR ë¡œê·¸ì¸
aws ecr get-login-password --region ap-northeast-2 | docker login --username AWS --password-stdin <AWS_ACCOUNT_ID>.dkr.ecr.ap-northeast-2.amazonaws.com

# íƒœê·¸ ë° í‘¸ì‹œ
docker tag user-service:latest <AWS_ACCOUNT_ID>.dkr.ecr.ap-northeast-2.amazonaws.com/user-service:latest
docker push <AWS_ACCOUNT_ID>.dkr.ecr.ap-northeast-2.amazonaws.com/user-service:latest

# K8s ë°°í¬
kubectl apply -f k8s/deployment.yaml

# í™•ì¸
kubectl get pods -n tiketi-production -l app=user-service
kubectl logs -n tiketi-production <POD_NAME>
```

#### Event Service ë¶„ë¦¬

**ë™ì¼í•œ íŒ¨í„´ìœ¼ë¡œ ì§„í–‰**:
1. `services/event-service` ë””ë ‰í† ë¦¬ ìƒì„±
2. `backend/src/routes/events.js` ë³µì‚¬
3. DB ì—°ê²°ì„ `events_db`ë¡œ ë³€ê²½
4. Dockerfile ì‘ì„±
5. K8s ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì‘ì„±
6. ë¹Œë“œ ë° ë°°í¬

### Week 4: Reservation Service & Payment Service

#### Reservation Service ë¶„ë¦¬

**íŠ¹ë³„ ê³ ë ¤ì‚¬í•­**:
- Redis ë¶„ì‚° ë½ ì‚¬ìš©
- Event Serviceì™€ í†µì‹  í•„ìš”
- íŠ¸ëœì­ì…˜ ê´€ë¦¬

**ì„œë¹„ìŠ¤ ê°„ í†µì‹  êµ¬í˜„**:

```javascript
// services/reservation-service/src/clients/event-client.js
const axios = require('axios');

class EventClient {
  constructor() {
    this.baseURL = process.env.EVENT_SERVICE_URL || 'http://event-service';
  }

  async getEvent(eventId) {
    const response = await axios.get(`${this.baseURL}/api/events/${eventId}`);
    return response.data;
  }

  async getAvailableSeats(eventId) {
    const response = await axios.get(`${this.baseURL}/api/seats/event/${eventId}`);
    return response.data;
  }
}

module.exports = new EventClient();
```

#### Payment Service ë¶„ë¦¬ (Toss Payments í†µí•©)

**Step 1: Payment Service ìƒì„±**

```bash
mkdir -p services/payment-service/src/{routes,config,services}
cd services/payment-service

npm init -y
npm install express dotenv pg @tosspayments/payment-sdk-node axios winston
```

**Step 2: Toss Payments í†µí•©**

```javascript
// services/payment-service/src/services/toss-client.js
const axios = require('axios');

class TossPaymentsClient {
  constructor() {
    this.secretKey = process.env.TOSS_SECRET_KEY;
    this.clientKey = process.env.TOSS_CLIENT_KEY;
    this.baseURL = 'https://api.tosspayments.com/v1';
  }

  // ê²°ì œ ìŠ¹ì¸
  async confirmPayment({ paymentKey, orderId, amount }) {
    const response = await axios.post(
      `${this.baseURL}/payments/confirm`,
      { paymentKey, orderId, amount },
      {
        headers: {
          'Authorization': `Basic ${Buffer.from(this.secretKey + ':').toString('base64')}`,
          'Content-Type': 'application/json'
        }
      }
    );
    return response.data;
  }

  // ê²°ì œ ì·¨ì†Œ (í™˜ë¶ˆ)
  async cancelPayment({ paymentKey, cancelReason }) {
    const response = await axios.post(
      `${this.baseURL}/payments/${paymentKey}/cancel`,
      { cancelReason },
      {
        headers: {
          'Authorization': `Basic ${Buffer.from(this.secretKey + ':').toString('base64')}`,
          'Content-Type': 'application/json'
        }
      }
    );
    return response.data;
  }
}

module.exports = new TossPaymentsClient();
```

**Step 3: Payment Routes**

```javascript
// services/payment-service/src/routes/payments.js
const express = require('express');
const db = require('../config/database');
const tossClient = require('../services/toss-client');
const router = express.Router();

// ê²°ì œ ìš”ì²­
router.post('/toss/request', async (req, res, next) => {
  try {
    const { reservationId, amount, customerName, customerEmail } = req.body;

    // ê²°ì œ ìš”ì²­ ì €ì¥
    const result = await db.query(`
      INSERT INTO payments (reservation_id, amount, status, provider, order_id)
      VALUES ($1, $2, 'PENDING', 'TOSS', $3)
      RETURNING *
    `, [reservationId, amount, `ORDER_${Date.now()}_${reservationId}`]);

    const payment = result.rows[0];

    // Toss ê²°ì œ URL ìƒì„±
    const paymentUrl = `https://pay.toss.im/web?
      amount=${amount}
      &orderId=${payment.order_id}
      &orderName=í‹°ì¼“ì˜ˆë§¤
      &customerName=${customerName}
      &customerEmail=${customerEmail}
      &successUrl=${process.env.PAYMENT_SUCCESS_URL}
      &failUrl=${process.env.PAYMENT_FAIL_URL}
      &clientKey=${tossClient.clientKey}
    `.replace(/\s/g, '');

    res.json({
      paymentId: payment.id,
      paymentUrl,
      orderId: payment.order_id
    });
  } catch (error) {
    next(error);
  }
});

// ê²°ì œ ìŠ¹ì¸
router.post('/toss/confirm', async (req, res, next) => {
  try {
    const { paymentKey, orderId, amount } = req.body;

    // Toss API í˜¸ì¶œ
    const result = await tossClient.confirmPayment({
      paymentKey,
      orderId,
      amount
    });

    // ê²°ì œ ìƒíƒœ ì—…ë°ì´íŠ¸
    await db.query(`
      UPDATE payments
      SET status = 'COMPLETED',
          payment_key = $1,
          approved_at = NOW()
      WHERE order_id = $2
    `, [paymentKey, orderId]);

    // Reservation Serviceì— ì•Œë¦¼ (ë©”ì‹œì§€ í or ì§ì ‘ í˜¸ì¶œ)
    // TODO: RabbitMQ publish

    res.json({
      success: true,
      paymentKey,
      approvedAt: result.approvedAt
    });
  } catch (error) {
    // ì‹¤íŒ¨ ì‹œ ê²°ì œ ìƒíƒœ ì—…ë°ì´íŠ¸
    await db.query(`
      UPDATE payments
      SET status = 'FAILED',
          error_message = $1
      WHERE order_id = $2
    `, [error.message, orderId]);

    next(error);
  }
});

// Webhook (í™˜ë¶ˆ ë“±)
router.post('/toss/webhook', async (req, res) => {
  const { eventType, data } = req.body;

  if (eventType === 'PAYMENT_CANCELED') {
    // í™˜ë¶ˆ ì²˜ë¦¬
    await db.query(`
      UPDATE payments
      SET status = 'CANCELLED'
      WHERE payment_key = $1
    `, [data.paymentKey]);
  }

  res.json({ received: true });
});

module.exports = router;
```

### Week 5: Queue Service, Media Service, Analytics Service

#### Queue Service (Socket.IO)

**íŠ¹ì§•**: Stateful ì„œë¹„ìŠ¤ - Sticky Session í•„ìš”

```yaml
# services/queue-service/k8s/deployment.yaml
apiVersion: v1
kind: Service
metadata:
  name: queue-service
  namespace: tiketi-production
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
spec:
  selector:
    app: queue-service
  ports:
  - protocol: TCP
    port: 80
    targetPort: 3001
  type: LoadBalancer
  sessionAffinity: ClientIP  # Sticky Session
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800  # 3 hours
```

#### Analytics Service (ì‹ ê·œ ê°œë°œ)

**Step 1: Analytics Service ìƒì„±**

```bash
mkdir -p services/analytics-service/src/{routes,services,cron}
cd services/analytics-service
npm init -y
npm install express dotenv pg redis axios winston node-cron
```

**Step 2: ì´ë²¤íŠ¸ ìˆ˜ì§‘ API**

```javascript
// services/analytics-service/src/routes/analytics.js
const express = require('express');
const db = require('../config/database');
const redis = require('../config/redis');
const router = express.Router();

// ì´ë²¤íŠ¸ íŠ¸ë˜í‚¹
router.post('/track', async (req, res) => {
  try {
    const { eventType, artistId, eventId, metadata } = req.body;

    // ì´ë²¤íŠ¸ ì €ì¥
    await db.query(`
      INSERT INTO analytics_events (event_type, aggregate_id, data)
      VALUES ($1, $2, $3)
    `, [eventType, artistId, JSON.stringify({ eventId, ...metadata })]);

    // Redis ì‹¤ì‹œê°„ ì¹´ìš´í„° ì¦ê°€
    const today = new Date().toISOString().split('T')[0].replace(/-/g, '');
    await redis.incr(`artist:${artistId}:views:${today}`);

    res.json({ success: true });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// ê°€ìˆ˜ë³„ íŠ¸ë˜í”½ ì¡°íšŒ
router.get('/artist/:artistId/traffic', async (req, res) => {
  try {
    const { artistId } = req.params;
    const { startDate, endDate } = req.query;

    const result = await db.query(`
      SELECT
        date,
        page_views,
        unique_visitors,
        avg_session_duration
      FROM artist_traffic
      WHERE artist_id = $1
        AND date BETWEEN $2 AND $3
      ORDER BY date ASC
    `, [artistId, startDate, endDate]);

    res.json({
      artistId,
      traffic: result.rows
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// ë§¤ì¶œ í†µê³„ ì¡°íšŒ
router.get('/revenue/stats', async (req, res) => {
  try {
    const { period = 'monthly' } = req.query;

    const result = await db.query(`
      SELECT
        period_start,
        total_revenue,
        tickets_sold,
        avg_ticket_price
      FROM revenue_stats
      WHERE period_type = $1
      ORDER BY period_start DESC
      LIMIT 12
    `, [period]);

    res.json({
      period,
      data: result.rows
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

module.exports = router;
```

**Step 3: ì£¼ê¸°ì  ì§‘ê³„ Cron Job**

```javascript
// services/analytics-service/src/cron/aggregator.js
const cron = require('node-cron');
const db = require('../config/database');
const redis = require('../config/redis');
const { logger } = require('../utils/logger');

// ë§¤ ì‹œê°„ ì§‘ê³„
cron.schedule('0 * * * *', async () => {
  try {
    logger.info('ğŸ”„ Starting hourly aggregation...');

    const now = new Date();
    const today = now.toISOString().split('T')[0];

    // Redisì—ì„œ ëª¨ë“  ì¹´ìš´í„° ê°€ì ¸ì˜¤ê¸°
    const keys = await redis.keys('artist:*:views:*');

    for (const key of keys) {
      const match = key.match(/artist:(.+):views:(\d+)/);
      if (!match) continue;

      const [_, artistId, dateStr] = match;
      const views = await redis.get(key);

      // DBì— ì €ì¥
      await db.query(`
        INSERT INTO artist_traffic (artist_id, date, page_views)
        VALUES ($1, $2, $3)
        ON CONFLICT (artist_id, date)
        DO UPDATE SET page_views = artist_traffic.page_views + EXCLUDED.page_views
      `, [artistId, dateStr, parseInt(views)]);

      // ì–´ì œ ë°ì´í„°ëŠ” Redisì—ì„œ ì‚­ì œ
      if (dateStr < today.replace(/-/g, '')) {
        await redis.del(key);
      }
    }

    logger.info('âœ… Hourly aggregation completed');
  } catch (error) {
    logger.error('âŒ Hourly aggregation failed:', error);
  }
});

module.exports = { start: () => logger.info('ğŸ“Š Analytics aggregator started') };
```

---

## ğŸŒŸ Phase 3: ì‹ ê·œ ê¸°ëŠ¥ ë° í†µí•© (Week 6-7)

### Week 6: í†µí•© í…ŒìŠ¤íŠ¸ ë° API Gateway ì„¤ì •

#### Ingress ì„¤ì • (API Gateway)

```yaml
# k8s/ingress/api-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: tiketi-api-ingress
  namespace: tiketi-production
  annotations:
    kubernetes.io/ingress.class: "nginx"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/rate-limit: "100"
spec:
  tls:
  - hosts:
    - api.tiketi.gg
    secretName: tiketi-api-tls
  rules:
  - host: api.tiketi.gg
    http:
      paths:
      # User Service
      - path: /api/users
        pathType: Prefix
        backend:
          service:
            name: user-service
            port:
              number: 80

      # Event Service
      - path: /api/events
        pathType: Prefix
        backend:
          service:
            name: event-service
            port:
              number: 80

      # Reservation Service
      - path: /api/reservations
        pathType: Prefix
        backend:
          service:
            name: reservation-service
            port:
              number: 80

      - path: /api/seats
        pathType: Prefix
        backend:
          service:
            name: reservation-service
            port:
              number: 80

      # Payment Service
      - path: /api/payments
        pathType: Prefix
        backend:
          service:
            name: payment-service
            port:
              number: 80

      # Analytics Service
      - path: /api/analytics
        pathType: Prefix
        backend:
          service:
            name: analytics-service
            port:
              number: 80

      # Admin Service
      - path: /api/admin
        pathType: Prefix
        backend:
          service:
            name: admin-service
            port:
              number: 80

      # Media Service
      - path: /api/media
        pathType: Prefix
        backend:
          service:
            name: media-service
            port:
              number: 80
```

### Week 7: CI/CD íŒŒì´í”„ë¼ì¸

#### GitHub Actions Workflow

```yaml
# .github/workflows/deploy-user-service.yml
name: Deploy User Service

on:
  push:
    branches: [main]
    paths:
      - 'services/user-service/**'

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-northeast-2

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Build and push Docker image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: user-service
          IMAGE_TAG: ${{ github.sha }}
        run: |
          cd services/user-service
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --region ap-northeast-2 --name tiketi-prod

      - name: Deploy to EKS
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          kubectl set image deployment/user-service \
            user-service=$ECR_REGISTRY/user-service:$IMAGE_TAG \
            -n tiketi-production

          kubectl rollout status deployment/user-service -n tiketi-production
```

---

## ğŸ“Š Phase 4: ëª¨ë‹ˆí„°ë§ ë° ìµœì í™” (Week 8-10)

### Week 8: ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì„¤ì¹˜

#### Prometheus & Grafana

```bash
# Prometheus ì„¤ì¹˜
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace tiketi-monitoring \
  --create-namespace

# Grafana ì ‘ì†
kubectl port-forward -n tiketi-monitoring svc/prometheus-grafana 3000:80

# ë¡œê·¸ì¸: admin / prom-operator
```

### Week 9-10: í”„ë¡œë•ì…˜ ë°°í¬

#### Blue/Green ë°°í¬ ì „ëµ

```bash
# Green í™˜ê²½ ë°°í¬ (ìƒˆ ë²„ì „)
kubectl apply -f k8s/production/green/

# íŠ¸ë˜í”½ í™•ì¸
kubectl get ingress -n tiketi-production

# í…ŒìŠ¤íŠ¸ í›„ íŠ¸ë˜í”½ ì „í™˜
kubectl patch ingress tiketi-api-ingress -n tiketi-production \
  --type='json' -p='[{"op": "replace", "path": "/spec/rules/0/http/paths/0/backend/service/name", "value":"user-service-green"}]'

# í™•ì¸ í›„ Blue í™˜ê²½ ì œê±°
kubectl delete -f k8s/production/blue/
```

---

## âœ… ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì¸í”„ë¼
- [ ] EKS í´ëŸ¬ìŠ¤í„° ìƒì„±
- [ ] VPC ë° Subnet êµ¬ì„±
- [ ] RDS PostgreSQL ìƒì„±
- [ ] ElastiCache Redis ìƒì„±
- [ ] S3 Bucket ìƒì„±
- [ ] Ingress Controller ì„¤ì¹˜
- [ ] Cert-Manager ì„¤ì¹˜

### ì„œë¹„ìŠ¤ ê°œë°œ
- [ ] User Service (+ Google OAuth)
- [ ] Event Service
- [ ] Reservation Service
- [ ] Payment Service (+ Toss Payments)
- [ ] Queue Service
- [ ] Analytics Service (ì‹ ê·œ)
- [ ] Admin Service
- [ ] Media Service

### ë°ì´í„°ë² ì´ìŠ¤
- [ ] ì„œë¹„ìŠ¤ë³„ DB ìŠ¤í‚¤ë§ˆ ì‘ì„±
- [ ] ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
- [ ] Foreign Key ì œê±° (ì„œë¹„ìŠ¤ ê°„ ë…ë¦½ì„±)
- [ ] ì¸ë±ìŠ¤ ìµœì í™”

### CI/CD
- [ ] GitHub Actions ì›Œí¬í”Œë¡œìš°
- [ ] ECR Repository ìƒì„±
- [ ] K8s ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì‘ì„±
- [ ] Secrets ê´€ë¦¬

### í…ŒìŠ¤íŠ¸
- [ ] Unit Test
- [ ] Integration Test
- [ ] E2E Test
- [ ] Load Test (k6)

### ë°°í¬
- [ ] Staging í™˜ê²½ ë°°í¬
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
- [ ] Production ë°°í¬ (Blue/Green)
- [ ] ëª¨ë‹ˆí„°ë§ ì„¤ì •

---

**ì‘ì„±ì¼**: 2025-12-05
**ì‘ì„±ì**: Claude
**ë²„ì „**: 1.0
